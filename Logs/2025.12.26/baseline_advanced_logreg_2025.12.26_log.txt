[INFO] === baseline_advanced_logreg ===
2025-12-27 10:37:12,733 INFO: Wczytywanie cech z pliku CSV...
2025-12-27 10:37:18,076 INFO: Wczytano cechy rozszerzone: (471031, 13)
2025-12-27 10:37:18,201 INFO: Użyte cechy: ['r_mean', 'g_mean', 'b_mean', 'r_std', 'g_std', 'b_std', 'h_mean', 'h_std', 's_mean', 'v_mean']
2025-12-27 10:37:18,212 INFO: Podział na zbiór treningowy i testowy...
2025-12-27 10:37:18,353 INFO: Rozmiar zbioru treningowego: (329721, 10), testowego: (141310, 10)
2025-12-27 10:37:18,353 INFO: Rozpoczynam trenowanie modelu LogisticRegression...
/home/vision/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.
2025-12-27 10:39:32,103 INFO: Trenowanie zakończone.
2025-12-27 10:39:32,114 INFO: Predykcja na zbiorze testowym...
Model zapisano do pliku: /mnt/c/Users/Dell/Desktop/Workplace/Repositories/ZegarBiologiczny/models/baseline_advanced_logreg_model.pkl

=== Wyniki modelu bazowego (cechy advanced + LogisticRegression) ===
Accuracy: 0.35829028377326444

Classification report:
              precision    recall  f1-score   support

           0       0.16      0.20      0.18      5370
           1       0.09      0.03      0.05      5370
           2       0.20      0.06      0.09      5372
           3       0.16      0.16      0.16      5372
           4       0.16      0.20      0.18      5371
           5       0.24      0.54      0.33      5371
           6       0.44      0.26      0.33      5371
           7       0.62      0.53      0.57      5368
           8       0.49      0.60      0.54      5366
           9       0.39      0.32      0.35      5085
          10       0.53      0.63      0.58      5190
          11       0.37      0.50      0.42      5364
          12       0.54      0.51      0.52      5696
          13       0.60      0.35      0.44      6420
          14       0.60      0.62      0.61      6244
          15       0.68      0.67      0.68      6440
          16       0.28      0.37      0.32      7216
          17       0.21      0.23      0.22      7519
          18       0.31      0.35      0.32      7519
          19       0.42      0.52      0.47      7519
          20       0.40      0.27      0.32      6656
          21       0.10      0.00      0.01      5371
          22       0.79      0.33      0.47      5370
          23       0.13      0.25      0.17      5370

    accuracy                           0.36    141310
   macro avg       0.37      0.35      0.35    141310
weighted avg       0.37      0.36      0.35    141310

Macierz pomyłek:
[[1090   63  219  131  813  952   83    0    0    0    0    0    0    0
     0    0  936   30   33    0  157    0    0  863]
 [1206  167  259  280  832  955    0    0    0    0    0    0    0    0
     0    0  935    0    4    0    0    0    0  732]
 [ 737  162  335  588  746 1478    0    0    0    0    0    0    0    0
     0    0  630    0    0    0    0    0    0  696]
 [ 172  234  251  853 1036 1575    0    0    0    0    0    0    0    0
     0    0  496    0    0    0    0    0    0  755]
 [ 286  305  188  939 1058 1959    0    0    0    0    0    0    0    0
     0    0   57    0    0    0    0    0    0  579]
 [ 259  403   96  718  342 2908    0    0    0    0    0    0    0    0
     0    0   63    0    2    0    0    0    0  580]
 [  17  104    0 1069  268  989 1402    2    0    0    0    0   17   22
    26  386  212    0    0   16  130    0  103  608]
 [   0    0    0    0    0    0  113 2821  668  312    0   66    0    8
   548  832    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0  456 3239 1017  405  230   14    5
     0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0 2074 1617 1230  164    0    0
     0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    5  195  491 3288 1077    2    0
    39   93    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0  745    0  347  703 2694  345  244
   263   23    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    1  198    0   27  334 1483 2887  477
   114   46   15   63   51    0    0    0    0    0]
 [   0    0    0    0    0    0    3    5  257  194  162 1126 1096 2242
  1059  221   11    2   40    0    2    0    0    0]
 [   0    0    0    0    0    0    0  128  198  190   91  473  394  482
  3870  418    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0  508  163    0    0    0   52  630  220
   482 4333    9    0    0    7    0    0   36    0]
 [   0   17    0  120  270  223  230    2    0    0    0    0    3    7
     0   18 2672  606 1529  992  193   16    0  318]
 [   8   23    0  153  127  131   12   23    0    0    0    0    0    0
     0    0 1290 1734  986 1602  499   98    0  833]
 [  85   52   56   37  157    0    0    0    0    0    0    0    0    0
     0    0  969 1565 2599  651  315   60    0  973]
 [ 600  136   49   61  161   94  156    0    0    0    0    0    0    0
     0    0   14  818  497 3923  447    0    4  559]
 [ 747   50    0    0    0    7  486    0    0    0    0    0    0    0
     0    0  315  924  598 1405 1769    0    0  355]
 [1228    4    0   85   11    2  117    0    0    0    0    0    0    0
     0    0  204 1248 1237  422  348   20  246  199]
 [ 363    7    0   33   68   87   26    0    0    0    0    0    0    0
     0    0  394  432  612  300  214    0 1774 1060]
 [ 157  232  237  310  646  696   15    0    0    0    0    0    0    0
     0    0  178  854  297    3  319    0   91 1335]]
